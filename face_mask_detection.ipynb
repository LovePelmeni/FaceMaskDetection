{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mloooo/notebook5a39d105b9?scriptVersionId=145235832\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-04T14:45:35.109698Z","iopub.execute_input":"2023-10-04T14:45:35.110032Z","iopub.status.idle":"2023-10-04T14:45:35.125789Z","shell.execute_reply.started":"2023-10-04T14:45:35.110006Z","shell.execute_reply":"2023-10-04T14:45:35.124795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport skimage\nimport numpy\nimport typing\nimport warnings \nimport os\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport pandas\nfrom PIL import Image\nimport seaborn\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:35.127767Z","iopub.execute_input":"2023-10-04T14:45:35.128379Z","iopub.status.idle":"2023-10-04T14:45:35.134116Z","shell.execute_reply.started":"2023-10-04T14:45:35.128332Z","shell.execute_reply":"2023-10-04T14:45:35.133064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_kaggle ='../input/face-mask-detection'\ndata_kaggle ='../input/face-mask-detection/dataset'\nwith_mask ='..../input/face-mask-detection/dataset/with_mask'\nwithout_mask='../input/face-mask-detection/dataset/without_mask'\n\nclass_data= ['with_mask','without_mask']\nlen_class_data = len(class_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:35.135441Z","iopub.execute_input":"2023-10-04T14:45:35.1362Z","iopub.status.idle":"2023-10-04T14:45:35.147338Z","shell.execute_reply.started":"2023-10-04T14:45:35.13617Z","shell.execute_reply":"2023-10-04T14:45:35.146403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_count = {}\ntrain_data = []\n\nfor i , class_data in tqdm(enumerate(class_data)):\n    class_folder = os.path.join(data_kaggle,class_data)\n    label = class_data\n    image_count[class_data] = []\n    \n    for path in os.listdir(os.path.join(class_folder)):\n        image_count[class_data].append(class_data)\n        train_data.append(['{}/{}'.format(class_data, path), i, class_data])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:35.149703Z","iopub.execute_input":"2023-10-04T14:45:35.150418Z","iopub.status.idle":"2023-10-04T14:45:35.165094Z","shell.execute_reply.started":"2023-10-04T14:45:35.150388Z","shell.execute_reply":"2023-10-04T14:45:35.164155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pandas.DataFrame(\n    train_data, \n    columns=['path', 'class', 'name']\n)\ndf['full_path'] = df['path'].apply(\n    lambda item: os.path.join(data_kaggle, item)\n)\ndf['image'] = df['full_path'].apply(func=lambda item: Image.open(item))\n\n\ndef validate_channels(img): \n    if numpy.array(img).shape[2] == 4:\n        img = Image.fromarray(\n        cv2.cvtColor(numpy.array(img), cv2.COLOR_RGBA2RGB))\n    return img\n\ndf['image'] = df['image'].apply(func=validate_channels)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:35.166441Z","iopub.execute_input":"2023-10-04T14:45:35.167005Z","iopub.status.idle":"2023-10-04T14:45:42.00301Z","shell.execute_reply.started":"2023-10-04T14:45:35.166975Z","shell.execute_reply":"2023-10-04T14:45:42.002034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seaborn.countplot(x=df['class'])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:42.004387Z","iopub.execute_input":"2023-10-04T14:45:42.004705Z","iopub.status.idle":"2023-10-04T14:45:42.190595Z","shell.execute_reply.started":"2023-10-04T14:45:42.004673Z","shell.execute_reply":"2023-10-04T14:45:42.189663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Smoothing and Filtering Noisy images","metadata":{}},{"cell_type":"code","source":"def bilateral_filtering(image, diameter: int, sigma_space: int, sigma_color: int):\n    \n    if not isinstance(image, numpy.ndarray):\n        image = numpy.array(image)\n        \n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    new_img = cv2.bilateralFilter(\n        src=gray_image, \n        d=diameter,\n        sigmaColor=sigma_color, \n        sigmaSpace=sigma_space,\n    )\n    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return rgb_image\n\ndef sharpen_image(blur_image, orig_image, sharpen_factor):\n    new_img = orig_image - blur_image \n    return orig_image + (sharpen_factor * new_img)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:42.19231Z","iopub.execute_input":"2023-10-04T14:45:42.192644Z","iopub.status.idle":"2023-10-04T14:45:42.198769Z","shell.execute_reply.started":"2023-10-04T14:45:42.192614Z","shell.execute_reply":"2023-10-04T14:45:42.197617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resizing Image","metadata":{}},{"cell_type":"code","source":"HEIGHT = 512\nWIDTH = 512","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:42.200044Z","iopub.execute_input":"2023-10-04T14:45:42.200869Z","iopub.status.idle":"2023-10-04T14:45:42.211935Z","shell.execute_reply.started":"2023-10-04T14:45:42.200839Z","shell.execute_reply":"2023-10-04T14:45:42.211123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adjusting image contrast","metadata":{}},{"cell_type":"code","source":"import numpy \n\ndef adjust_object_contrast(img, alpha: float, beta: float):\n    conv_img = cv2.convertScaleAbs(\n    img, alpha=alpha, beta=beta)\n    return conv_img\n\ndef gamma_correction(img, gamma):\n    float_img = img.astype(numpy.float32) / 255.0\n    corr_img = numpy.power(float_img, 1 / gamma)\n    new_img = (corr_img * 255).astype(numpy.uint8)\n    return new_img\n\ndef adjust_local_clahe(img, clip_limit: int=3.0, tile_grid_size: tuple=(8, 8)):\n    \n    lab_img = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n    l, a, b = cv2.split(lab_img)\n    \n    clahe = cv2.createCLAHE(clip_limit, tile_grid_size)\n    clahed_l = clahe.apply(l)\n    \n    merged_img = cv2.merge((clahed_l, a, b))\n    converted_rgb = cv2.cvtColor(img, cv2.COLOR_LAB2BGR)\n    return converted_rgb\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:42.215804Z","iopub.execute_input":"2023-10-04T14:45:42.216584Z","iopub.status.idle":"2023-10-04T14:45:42.224266Z","shell.execute_reply.started":"2023-10-04T14:45:42.216554Z","shell.execute_reply":"2023-10-04T14:45:42.223289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resizing images","metadata":{}},{"cell_type":"code","source":"def nearest_neighbor_interpolation(img: numpy.ndarray, height, width):\n    new_img = cv2.resize(img, (height, width), cv2.INTER_NEAREST)\n    return new_img\n\ndef bilinear_interpolation(img: numpy.ndarray, height, width):\n    new_img = cv2.resize(img, (height, width), cv2.INTER_LINEAR)\n    return new_img\n\ndef bicubic_interpolation(img: numpy.ndarray, height, width):\n    new_img = cv2.resize(img, (height, width), cv2.INTER_CUBIC)\n    return new_img","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:42.22562Z","iopub.execute_input":"2023-10-04T14:45:42.22623Z","iopub.status.idle":"2023-10-04T14:45:42.236553Z","shell.execute_reply.started":"2023-10-04T14:45:42.2262Z","shell.execute_reply":"2023-10-04T14:45:42.2357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nblurred_images = []\nfor image in df['image'].tolist():\n    \n    contrasted_img = adjust_local_clahe(numpy.array(image))\n    corrected_img = gamma_correction(numpy.array(image), gamma=1.8)\n    blurred_images.append(corrected_img)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:42.23766Z","iopub.execute_input":"2023-10-04T14:45:42.239383Z","iopub.status.idle":"2023-10-04T14:45:57.476104Z","shell.execute_reply.started":"2023-10-04T14:45:42.239336Z","shell.execute_reply":"2023-10-04T14:45:57.475055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HEIGHT = 512\nWIDTH = 512","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:57.477422Z","iopub.execute_input":"2023-10-04T14:45:57.478592Z","iopub.status.idle":"2023-10-04T14:45:57.482898Z","shell.execute_reply.started":"2023-10-04T14:45:57.478558Z","shell.execute_reply":"2023-10-04T14:45:57.481925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms \nfrom torchvision.transforms import v2 \nfrom PIL import Image\n\ntrain_transformations = [\n    transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=15),\n    transforms.Resize(size=(HEIGHT, WIDTH), \n    interpolation=Image.NEAREST),\n    v2.RandomAdjustSharpness(sharpness_factor=1.5),\n\n]\n\nvalidation_transformations = [\n    transforms.ToTensor(),\n    transforms.Resize(size=(HEIGHT, WIDTH), \n    interpolation=Image.NEAREST),\n]","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:57.484279Z","iopub.execute_input":"2023-10-04T14:45:57.4852Z","iopub.status.idle":"2023-10-04T14:45:57.49598Z","shell.execute_reply.started":"2023-10-04T14:45:57.485163Z","shell.execute_reply":"2023-10-04T14:45:57.495268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"from torch.utils import data\nimport torch\n\nclass ImageDataset(data.Dataset):\n    \n    def __init__(self, labels, images, transform=None):\n        self.labels = labels \n        self.images = images \n        self.transform = transforms.Compose(transform) if transform is not None else None\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, key):\n        if key >= len(self.labels): return \n        label = self.labels[key]\n        if self.transform is not None:\n            image = self.transform(self.images[key])\n        else: image = self.images[key]\n        return label, image","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:57.497117Z","iopub.execute_input":"2023-10-04T14:45:57.49795Z","iopub.status.idle":"2023-10-04T14:45:57.509646Z","shell.execute_reply.started":"2023-10-04T14:45:57.49792Z","shell.execute_reply":"2023-10-04T14:45:57.508862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = ImageDataset(\n    labels=df['class'].tolist(),\n    images=blurred_images,\n    transform=None\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:57.510934Z","iopub.execute_input":"2023-10-04T14:45:57.511338Z","iopub.status.idle":"2023-10-04T14:45:57.522977Z","shell.execute_reply.started":"2023-10-04T14:45:57.511308Z","shell.execute_reply":"2023-10-04T14:45:57.522068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:57.52431Z","iopub.execute_input":"2023-10-04T14:45:57.524995Z","iopub.status.idle":"2023-10-04T14:45:57.535341Z","shell.execute_reply.started":"2023-10-04T14:45:57.524961Z","shell.execute_reply":"2023-10-04T14:45:57.534313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:57.536577Z","iopub.execute_input":"2023-10-04T14:45:57.537218Z","iopub.status.idle":"2023-10-04T14:45:57.545291Z","shell.execute_reply.started":"2023-10-04T14:45:57.537189Z","shell.execute_reply":"2023-10-04T14:45:57.544294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices = numpy.arange(len(dataset.images))\ntrain_indices, test_indices = train_test_split(\n    indices, \n    stratify=dataset.labels, \n    test_size=0.3\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:57.546549Z","iopub.execute_input":"2023-10-04T14:45:57.547488Z","iopub.status.idle":"2023-10-04T14:45:57.561483Z","shell.execute_reply.started":"2023-10-04T14:45:57.54742Z","shell.execute_reply":"2023-10-04T14:45:57.560542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\ntraining_set = ImageDataset(\n    labels=numpy.array(dataset.labels)[train_indices],\n    images=numpy.array(dataset.images)[train_indices],\n    transform=train_transformations\n)\n\nvalidation_set = ImageDataset(\n    labels=numpy.array(dataset.labels)[test_indices],\n    images=numpy.array(dataset.images)[test_indices],\n    transform=validation_transformations\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:57.562677Z","iopub.execute_input":"2023-10-04T14:45:57.563391Z","iopub.status.idle":"2023-10-04T14:45:57.575844Z","shell.execute_reply.started":"2023-10-04T14:45:57.563344Z","shell.execute_reply":"2023-10-04T14:45:57.574688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(training_set)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:57.577154Z","iopub.execute_input":"2023-10-04T14:45:57.577892Z","iopub.status.idle":"2023-10-04T14:45:57.587686Z","shell.execute_reply.started":"2023-10-04T14:45:57.577857Z","shell.execute_reply":"2023-10-04T14:45:57.586737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(validation_set)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:57.589025Z","iopub.execute_input":"2023-10-04T14:45:57.589525Z","iopub.status.idle":"2023-10-04T14:45:57.601294Z","shell.execute_reply.started":"2023-10-04T14:45:57.589497Z","shell.execute_reply":"2023-10-04T14:45:57.600101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fg, ax = plt.subplots(1, 2)\nseaborn.countplot(ax=ax[0], x=training_set.labels)\nseaborn.countplot(ax=ax[1], x=validation_set.labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:57.605922Z","iopub.execute_input":"2023-10-04T14:45:57.606617Z","iopub.status.idle":"2023-10-04T14:45:57.897607Z","shell.execute_reply.started":"2023-10-04T14:45:57.606589Z","shell.execute_reply":"2023-10-04T14:45:57.89672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fg, ax = plt.subplots(3, 2)\nax[0, 0].imshow(training_set.images[0])\nax[0, 1].imshow(training_set.images[1])\nax[1, 0].imshow(training_set.images[2])\nax[1, 1].imshow(training_set.images[3])\nax[2, 0].imshow(training_set.images[4])\nax[2, 1].imshow(training_set.images[5])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:57.898974Z","iopub.execute_input":"2023-10-04T14:45:57.899335Z","iopub.status.idle":"2023-10-04T14:45:58.836193Z","shell.execute_reply.started":"2023-10-04T14:45:57.899247Z","shell.execute_reply":"2023-10-04T14:45:58.835261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating Image Processing","metadata":{}},{"cell_type":"code","source":"# for Transformed images\nfrom skimage.metrics import structural_similarity as ssim_scr\nfrom skimage import measure\n\ndef ssim_score(old_img, new_img, channel_axis):\n    return ssim_scr(old_img, new_img, channel_axis=channel_axis)\n\ndef normalized_cross_correlation(old_img, new_img):\n    \"\"\"\n    Function computes standard Normalized Cross Correlation\n    for given old and modified versions of the same image \n    \n    Args:\n        old_img (numpy.ndarray) - numpy.array object of old image\n        new_img (numpy.ndarray) - numpy.array object of the modified image\n    \"\"\"\n    img1 = (old_img - old_img.mean()) / old_img.std()\n    img2 = (new_img - new_img.mean()) / new_img.std()\n    return numpy.sum(img1 * img2) / (img1.shape[0] - 1)\n\n# For Noise-Recovered images\n\ndef niqe_score(distorted_image):\n    return measure.niqe(distorted_image)\n\ndef brisque_score(distorted_image):\n    return measure.brisque(distorted_image)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:58.83756Z","iopub.execute_input":"2023-10-04T14:45:58.838071Z","iopub.status.idle":"2023-10-04T14:45:58.845787Z","shell.execute_reply.started":"2023-10-04T14:45:58.83804Z","shell.execute_reply":"2023-10-04T14:45:58.844526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initializing data loaders","metadata":{}},{"cell_type":"code","source":"%%time\n\ntraining_loader = data.DataLoader(\n    training_set, \n    batch_size=32, \n    shuffle=True,\n)\n\nvalidation_loader = data.DataLoader(\n    validation_set,\n    batch_size=32,\n    shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:58.84705Z","iopub.execute_input":"2023-10-04T14:45:58.847597Z","iopub.status.idle":"2023-10-04T14:45:58.858914Z","shell.execute_reply.started":"2023-10-04T14:45:58.847561Z","shell.execute_reply":"2023-10-04T14:45:58.857886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\nmax_allocated = torch.cuda.max_memory_allocated()\n(max_allocated ** 2) / 1024","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:45:58.860313Z","iopub.execute_input":"2023-10-04T14:45:58.861308Z","iopub.status.idle":"2023-10-04T14:45:58.874445Z","shell.execute_reply.started":"2023-10-04T14:45:58.86128Z","shell.execute_reply":"2023-10-04T14:45:58.873421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initializing Classification Neural Network","metadata":{}},{"cell_type":"code","source":"from torchvision import models \nfrom torch import optim \nfrom torch import nn\nfrom tqdm import tqdm\nfrom torch import backends\n\nclass MaskRecNet(object):\n    \n    \"\"\"\n    Implementation of the ResNet50 Neural Network \n    for classifying human as 'with' or 'without' face mask\n    \"\"\"\n    def __init__(self, \n        weights, \n        num_classes: int,\n        learning_rate: float, \n        weight_decay: float, \n        loss_function,\n        max_epochs: int,\n    ):\n        self.network = models.resnet50(weights=weights)\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        self.network.fc = nn.Linear(\n            in_features=self.network.fc.in_features,\n            out_features=num_classes\n        )\n        \n        self.optimizer = optim.Adam(\n            self.network.parameters(), \n            lr=learning_rate,\n            weight_decay=weight_decay\n        )\n        \n        self.loss_function = loss_function \n        self.max_epochs = max_epochs\n    \n    \n    def freeze_layers(self, num_layers_to_freeze):\n        \"\"\"\n        Function freezes first N number of layers\n        in the network\n        \"\"\"\n        for i, param in enumerate(self.network.parameters()):\n            if i < num_layers_to_freeze:\n                param.requires_grad = False\n            else:\n                break\n            \n    def unfreeze_layers(self):\n        \"\"\"\n        Function unfreezes all\n        freezed layers of the network\n        \"\"\"\n        for idx, param in enumearte(self.network.parameters()):\n            if not param.requires_grad:\n                param.requires_grad = True\n            \n    def train(self, dataset: data.DataLoader):\n        \"\"\"\n        Function trains neural network on a given\n        training set of images\n        \n        Args:\n            - dataset (ImageDataset) - training set of images\n        \"\"\"\n        self.network.train()\n        \n        model = nn.DataParallel(self.network)\n        total_loss = []\n        \n        for epoch in range(self.max_epochs):\n            epoch_losses = []\n            \n            for labels, images in tqdm(dataset):\n                cuda_imgs = images.to(self.device)\n                predictions = model.forward(cuda_imgs).cpu()\n                loss = self.loss_function(predictions, labels)\n                \n                epoch_losses.append(loss.item())\n                \n                loss.backward()\n                self.optimizer.step()\n            \n            total_loss.append(sum(epoch_losses) / len(epoch_losses))\n            print('epoch - %s;' % (str(epoch + 1)))\n        return sum(total_loss) / len(total_loss)\n    \n    def evaluate(self, dataset: data.DataLoader):\n        \"\"\"\n        Function evaluates model on a given validation set\n        Args:\n            dataset - ImageDataset - non-augmented dataset with images\n        \"\"\"\n        self.network.eval()\n        model = nn.DataParallel(self.network)\n        \n        if len(dataset) == 0: return []\n        \n        predictions = []\n        with torch.no_grad():\n            \n            losses = []\n            for labels, images in tqdm(dataset):\n                cuda_imgs = images.to(self.device)\n                predictions = model.forward(cuda_imgs).cpu()\n                loss = self.loss_function(predictions, labels)\n                losses.append(loss.item())\n                \n        return sum(losses) / len(losses)\n    \n    \n    def predict(self, images: typing.List[Image.Image]):\n        \"\"\"\n        Function used for predicting\n        binary class of having 'face mask' put on or off\n        \n        Args:\n            images - list of PIL image objects\n        Returns:\n            list of predicted classes\n        \"\"\"\n        if not len(images): return \n        predictions = []\n        for image in dataset:\n            prediction = self.network.forward(image)\n            predictions.append(prediction)\n        return predictions\n    \ndef backward_trace_hook(module, grad_input, grad_output):\n    print('module - %s' % module)\n    print('grad input - ', grad_input)\n    print('grad output - ', grad_output)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T15:10:37.771002Z","iopub.execute_input":"2023-10-04T15:10:37.771328Z","iopub.status.idle":"2023-10-04T15:10:37.785005Z","shell.execute_reply.started":"2023-10-04T15:10:37.771299Z","shell.execute_reply":"2023-10-04T15:10:37.783924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MaskRecNet(\n    weights=models.ResNet50_Weights.DEFAULT,\n    num_classes=2,\n    learning_rate=3e-6,\n    loss_function=nn.CrossEntropyLoss(),\n    max_epochs=60,\n    weight_decay=0.01,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T15:10:41.918857Z","iopub.execute_input":"2023-10-04T15:10:41.919255Z","iopub.status.idle":"2023-10-04T15:10:42.441168Z","shell.execute_reply.started":"2023-10-04T15:10:41.919225Z","shell.execute_reply":"2023-10-04T15:10:42.440202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Freezing layers for transfer learning task","metadata":{}},{"cell_type":"code","source":"model.freeze_layers(45)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T15:10:46.327679Z","iopub.execute_input":"2023-10-04T15:10:46.328033Z","iopub.status.idle":"2023-10-04T15:10:46.333052Z","shell.execute_reply.started":"2023-10-04T15:10:46.328004Z","shell.execute_reply":"2023-10-04T15:10:46.331974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Neural Network","metadata":{}},{"cell_type":"code","source":"avg_loss = model.train(training_loader)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T15:10:48.44455Z","iopub.execute_input":"2023-10-04T15:10:48.444896Z","iopub.status.idle":"2023-10-04T15:10:52.244538Z","shell.execute_reply.started":"2023-10-04T15:10:48.444868Z","shell.execute_reply":"2023-10-04T15:10:52.242994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_loss","metadata":{"execution":{"iopub.status.busy":"2023-10-04T15:05:10.748595Z","iopub.execute_input":"2023-10-04T15:05:10.748989Z","iopub.status.idle":"2023-10-04T15:05:10.755521Z","shell.execute_reply.started":"2023-10-04T15:05:10.748957Z","shell.execute_reply":"2023-10-04T15:05:10.754419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating model on validation set","metadata":{}},{"cell_type":"code","source":"eval_loss = model.evaluate(validation_loader)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T15:05:13.567744Z","iopub.execute_input":"2023-10-04T15:05:13.568109Z","iopub.status.idle":"2023-10-04T15:05:15.691728Z","shell.execute_reply.started":"2023-10-04T15:05:13.568081Z","shell.execute_reply":"2023-10-04T15:05:15.690855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_loss","metadata":{"execution":{"iopub.status.busy":"2023-10-04T15:05:18.958145Z","iopub.execute_input":"2023-10-04T15:05:18.958508Z","iopub.status.idle":"2023-10-04T15:05:18.964331Z","shell.execute_reply.started":"2023-10-04T15:05:18.95848Z","shell.execute_reply":"2023-10-04T15:05:18.963498Z"},"trusted":true},"execution_count":null,"outputs":[]}]}