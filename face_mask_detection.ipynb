{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mloooo/notebook5a39d105b9?scriptVersionId=143799784\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-21T19:38:55.935678Z","iopub.execute_input":"2023-09-21T19:38:55.936673Z","iopub.status.idle":"2023-09-21T19:38:56.511781Z","shell.execute_reply.started":"2023-09-21T19:38:55.936637Z","shell.execute_reply":"2023-09-21T19:38:56.510709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport skimage\nimport numpy\nimport typing\nimport warnings \nimport os\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport pandas\nfrom PIL import Image\nimport seaborn\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:38:56.514364Z","iopub.execute_input":"2023-09-21T19:38:56.515276Z","iopub.status.idle":"2023-09-21T19:38:57.543642Z","shell.execute_reply.started":"2023-09-21T19:38:56.515236Z","shell.execute_reply":"2023-09-21T19:38:57.542628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_kaggle ='../input/face-mask-detection'\ndata_kaggle ='../input/face-mask-detection/dataset'\nwith_mask ='..../input/face-mask-detection/dataset/with_mask'\nwithout_mask='../input/face-mask-detection/dataset/without_mask'\n\nclass_data= ['with_mask','without_mask']\nlen_class_data = len(class_data)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:38:57.545083Z","iopub.execute_input":"2023-09-21T19:38:57.54544Z","iopub.status.idle":"2023-09-21T19:38:57.554531Z","shell.execute_reply.started":"2023-09-21T19:38:57.545404Z","shell.execute_reply":"2023-09-21T19:38:57.553534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_count = {}\ntrain_data = []\n\nfor i , class_data in tqdm(enumerate(class_data)):\n    class_folder = os.path.join(data_kaggle,class_data)\n    label = class_data\n    image_count[class_data] = []\n    \n    for path in os.listdir(os.path.join(class_folder)):\n        image_count[class_data].append(class_data)\n        train_data.append(['{}/{}'.format(class_data, path), i, class_data])","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:38:57.556172Z","iopub.execute_input":"2023-09-21T19:38:57.556645Z","iopub.status.idle":"2023-09-21T19:38:57.58222Z","shell.execute_reply.started":"2023-09-21T19:38:57.556611Z","shell.execute_reply":"2023-09-21T19:38:57.581166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pandas.DataFrame(\n    train_data, \n    columns=['path', 'class', 'name']\n)\ndf['full_path'] = df['path'].apply(\n    lambda item: os.path.join(data_kaggle, item)\n)\ndf['image'] = df['full_path'].apply(func=lambda item: Image.open(item))\n\n\ndef validate_channels(img): \n    if numpy.array(img).shape[2] == 4:\n        img = Image.fromarray(\n        cv2.cvtColor(numpy.array(img), cv2.COLOR_RGBA2RGB))\n    return img\n\ndf['image'] = df['image'].apply(func=validate_channels)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:38:57.586037Z","iopub.execute_input":"2023-09-21T19:38:57.586661Z","iopub.status.idle":"2023-09-21T19:39:09.863503Z","shell.execute_reply.started":"2023-09-21T19:38:57.586625Z","shell.execute_reply":"2023-09-21T19:39:09.862505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seaborn.countplot(x=df['class'])","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:09.865047Z","iopub.execute_input":"2023-09-21T19:39:09.865622Z","iopub.status.idle":"2023-09-21T19:39:10.113291Z","shell.execute_reply.started":"2023-09-21T19:39:09.865587Z","shell.execute_reply":"2023-09-21T19:39:10.112276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Smoothing and Filtering Noisy images","metadata":{}},{"cell_type":"code","source":"def bilateral_filtering(image, diameter: int, sigma_space: int, sigma_color: int):\n    \n    if not isinstance(image, numpy.ndarray):\n        image = numpy.array(image)\n        \n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    new_img = cv2.bilateralFilter(\n        src=gray_image, \n        d=diameter,\n        sigmaColor=sigma_color, \n        sigmaSpace=sigma_space,\n    )\n    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return rgb_image\n\ndef sharpen_image(blur_image, orig_image, sharpen_factor):\n    new_img = orig_image - blur_image \n    return orig_image + (sharpen_factor * new_img)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:10.114657Z","iopub.execute_input":"2023-09-21T19:39:10.115498Z","iopub.status.idle":"2023-09-21T19:39:10.12268Z","shell.execute_reply.started":"2023-09-21T19:39:10.115463Z","shell.execute_reply":"2023-09-21T19:39:10.12167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resizing Image","metadata":{}},{"cell_type":"code","source":"HEIGHT = 512\nWIDTH = 512","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:10.123995Z","iopub.execute_input":"2023-09-21T19:39:10.125022Z","iopub.status.idle":"2023-09-21T19:39:10.135165Z","shell.execute_reply.started":"2023-09-21T19:39:10.124994Z","shell.execute_reply":"2023-09-21T19:39:10.134068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adjusting image contrast","metadata":{}},{"cell_type":"code","source":"import numpy \n\ndef adjust_object_contrast(img, alpha: float, beta: float):\n    conv_img = cv2.convertScaleAbs(\n    img, alpha=alpha, beta=beta)\n    return conv_img\n\ndef gamma_correction(img, gamma):\n    float_img = img.astype(numpy.float32) / 255.0\n    corr_img = numpy.power(float_img, 1 / gamma)\n    new_img = (corr_img * 255).astype(numpy.uint8)\n    return new_img\n\ndef adjust_local_clahe(img, clip_limit: int=3.0, tile_grid_size: tuple=(8, 8)):\n    \n    lab_img = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n    l, a, b = cv2.split(lab_img)\n    \n    clahe = cv2.createCLAHE(clip_limit, tile_grid_size)\n    clahed_l = clahe.apply(l)\n    \n    merged_img = cv2.merge((clahed_l, a, b))\n    converted_rgb = cv2.cvtColor(img, cv2.COLOR_LAB2BGR)\n    return converted_rgb\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:10.136412Z","iopub.execute_input":"2023-09-21T19:39:10.136719Z","iopub.status.idle":"2023-09-21T19:39:10.148303Z","shell.execute_reply.started":"2023-09-21T19:39:10.136693Z","shell.execute_reply":"2023-09-21T19:39:10.147301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resizing images","metadata":{}},{"cell_type":"code","source":"def nearest_neighbor_interpolation(img: numpy.ndarray, height, width):\n    new_img = cv2.resize(img, (height, width), cv2.INTER_NEAREST)\n    return new_img\n\ndef bilinear_interpolation(img: numpy.ndarray, height, width):\n    new_img = cv2.resize(img, (height, width), cv2.INTER_LINEAR)\n    return new_img\n\ndef bicubic_interpolation(img: numpy.ndarray, height, width):\n    new_img = cv2.resize(img, (height, width), cv2.INTER_CUBIC)\n    return new_img","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:10.151019Z","iopub.execute_input":"2023-09-21T19:39:10.152222Z","iopub.status.idle":"2023-09-21T19:39:10.164119Z","shell.execute_reply.started":"2023-09-21T19:39:10.152184Z","shell.execute_reply":"2023-09-21T19:39:10.163029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nblurred_images = []\nfor image in df['image'].tolist():\n    \n    contrasted_img = adjust_local_clahe(numpy.array(image))\n    corrected_img = gamma_correction(numpy.array(image), gamma=1.8)\n    blurred_images.append(corrected_img)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:10.166975Z","iopub.execute_input":"2023-09-21T19:39:10.167731Z","iopub.status.idle":"2023-09-21T19:39:26.17868Z","shell.execute_reply.started":"2023-09-21T19:39:10.167697Z","shell.execute_reply":"2023-09-21T19:39:26.177522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms \nfrom torchvision.transforms import v2 \nfrom PIL import Image\n\ntrain_transformations = [\n    transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=15),\n    transforms.Resize(size=(HEIGHT, WIDTH), \n    interpolation=Image.NEAREST),\n    v2.RandomAdjustSharpness(sharpness_factor=1.5),\n]\n\nvalidation_transformations = [\n    transforms.ToTensor(),\n    transforms.Resize(size=(HEIGHT, WIDTH), \n    interpolation=Image.NEAREST),\n]","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:26.180057Z","iopub.execute_input":"2023-09-21T19:39:26.180931Z","iopub.status.idle":"2023-09-21T19:39:29.572658Z","shell.execute_reply.started":"2023-09-21T19:39:26.180894Z","shell.execute_reply":"2023-09-21T19:39:29.571552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"from torch.utils import data\nimport torch\n\nclass ImageDataset(data.Dataset):\n    \n    def __init__(self, labels, images, transform=None):\n        self.labels = labels \n        self.images = images \n        self.transform = transforms.Compose(transform) if transform is not None else None\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, key):\n        if key >= len(self.labels): return \n        label = self.labels[key]\n        if self.transform is not None:\n            image = self.transform(self.images[key])\n        else: image = self.images[key]\n        return label, image","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:29.574237Z","iopub.execute_input":"2023-09-21T19:39:29.574857Z","iopub.status.idle":"2023-09-21T19:39:29.582829Z","shell.execute_reply.started":"2023-09-21T19:39:29.574797Z","shell.execute_reply":"2023-09-21T19:39:29.58188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = ImageDataset(\n    labels=df['class'].tolist(),\n    images=blurred_images,\n    transform=None\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:29.588627Z","iopub.execute_input":"2023-09-21T19:39:29.589344Z","iopub.status.idle":"2023-09-21T19:39:29.600952Z","shell.execute_reply.started":"2023-09-21T19:39:29.589308Z","shell.execute_reply":"2023-09-21T19:39:29.59988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:29.602584Z","iopub.execute_input":"2023-09-21T19:39:29.603008Z","iopub.status.idle":"2023-09-21T19:39:29.614539Z","shell.execute_reply.started":"2023-09-21T19:39:29.602971Z","shell.execute_reply":"2023-09-21T19:39:29.613492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting data","metadata":{}},{"cell_type":"code","source":"from torch.utils import data\ntraining_size = int(0.7 * len(dataset))\nvalidation_size = len(dataset) - training_size\ntrain_set, valid_set = data.random_split(dataset, [training_size, validation_size])","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:29.616359Z","iopub.execute_input":"2023-09-21T19:39:29.616709Z","iopub.status.idle":"2023-09-21T19:39:29.642922Z","shell.execute_reply.started":"2023-09-21T19:39:29.616676Z","shell.execute_reply":"2023-09-21T19:39:29.641586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\ntraining_set = ImageDataset(\n    labels=numpy.array(dataset.labels)[train_set.indices],\n    images=numpy.array(dataset.images)[train_set.indices],\n    transform=train_transformations\n)\n\nvalidation_set = ImageDataset(\n    labels=numpy.array(dataset.labels)[valid_set.indices],\n    images=numpy.array(dataset.images)[valid_set.indices],\n    transform=validation_transformations\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:29.644332Z","iopub.execute_input":"2023-09-21T19:39:29.644627Z","iopub.status.idle":"2023-09-21T19:39:29.653681Z","shell.execute_reply.started":"2023-09-21T19:39:29.644601Z","shell.execute_reply":"2023-09-21T19:39:29.652567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(training_set)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:29.655326Z","iopub.execute_input":"2023-09-21T19:39:29.655984Z","iopub.status.idle":"2023-09-21T19:39:29.663478Z","shell.execute_reply.started":"2023-09-21T19:39:29.655942Z","shell.execute_reply":"2023-09-21T19:39:29.662511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(validation_set)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:29.664997Z","iopub.execute_input":"2023-09-21T19:39:29.665685Z","iopub.status.idle":"2023-09-21T19:39:29.675125Z","shell.execute_reply.started":"2023-09-21T19:39:29.665652Z","shell.execute_reply":"2023-09-21T19:39:29.673919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fg, ax = plt.subplots(1, 2)\nseaborn.countplot(ax=ax[0], x=training_set.labels)\nseaborn.countplot(ax=ax[1], x=validation_set.labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:29.67703Z","iopub.execute_input":"2023-09-21T19:39:29.677518Z","iopub.status.idle":"2023-09-21T19:39:30.053003Z","shell.execute_reply.started":"2023-09-21T19:39:29.677421Z","shell.execute_reply":"2023-09-21T19:39:30.051825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fg, ax = plt.subplots(3, 2)\nax[0, 0].imshow(training_set.images[0])\nax[0, 1].imshow(training_set.images[1])\nax[1, 0].imshow(training_set.images[2])\nax[1, 1].imshow(training_set.images[3])\nax[2, 0].imshow(training_set.images[4])\nax[2, 1].imshow(training_set.images[5])","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:30.054282Z","iopub.execute_input":"2023-09-21T19:39:30.055618Z","iopub.status.idle":"2023-09-21T19:39:31.469509Z","shell.execute_reply.started":"2023-09-21T19:39:30.055579Z","shell.execute_reply":"2023-09-21T19:39:31.467516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating Image Processing","metadata":{}},{"cell_type":"code","source":"# for Transformed images\nfrom skimage.metrics import structural_similarity as ssim_scr\nfrom skimage import measure\n\ndef ssim_score(old_img, new_img, channel_axis):\n    return ssim_scr(old_img, new_img, channel_axis=channel_axis)\n\ndef normalized_cross_correlation(old_img, new_img):\n    \"\"\"\n    Function computes standard Normalized Cross Correlation\n    for given old and modified versions of the same image \n    \n    Args:\n        old_img (numpy.ndarray) - numpy.array object of old image\n        new_img (numpy.ndarray) - numpy.array object of the modified image\n    \"\"\"\n    img1 = (old_img - old_img.mean()) / old_img.std()\n    img2 = (new_img - new_img.mean()) / new_img.std()\n    return numpy.sum(img1 * img2) / (img1.shape[0] - 1)\n\n# For Noise-Recovered images\n\ndef niqe_score(distorted_image):\n    return measure.niqe(distorted_image)\n\ndef brisque_score(distorted_image):\n    return measure.brisque(distorted_image)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:31.473775Z","iopub.execute_input":"2023-09-21T19:39:31.474262Z","iopub.status.idle":"2023-09-21T19:39:31.672771Z","shell.execute_reply.started":"2023-09-21T19:39:31.474226Z","shell.execute_reply":"2023-09-21T19:39:31.671287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initializing data loaders","metadata":{}},{"cell_type":"code","source":"%%time\n\ntraining_loader = data.DataLoader(\n    training_set, \n    batch_size=32, \n    shuffle=True,\n)\n\nvalidation_loader = data.DataLoader(\n    validation_set,\n    batch_size=32,\n    shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:31.674559Z","iopub.execute_input":"2023-09-21T19:39:31.67502Z","iopub.status.idle":"2023-09-21T19:39:31.682417Z","shell.execute_reply.started":"2023-09-21T19:39:31.674981Z","shell.execute_reply":"2023-09-21T19:39:31.680872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\nmax_allocated = torch.cuda.max_memory_allocated()\n(max_allocated ** 2) / 1024","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:31.684299Z","iopub.execute_input":"2023-09-21T19:39:31.685248Z","iopub.status.idle":"2023-09-21T19:39:31.698297Z","shell.execute_reply.started":"2023-09-21T19:39:31.685208Z","shell.execute_reply":"2023-09-21T19:39:31.697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initializing Classification Neural Network","metadata":{}},{"cell_type":"code","source":"from torchvision import models \nfrom torch import optim \nfrom torch import nn\nfrom tqdm import tqdm\nfrom torch import backends\n\nclass MaskRecNet(object):\n    \n    \"\"\"\n    Implementation of the ResNet50 Neural Network \n    for classifying human as 'with' or 'without' face mask\n    \"\"\"\n    def __init__(self, \n        weights, \n        num_classes: int,\n        learning_rate: float, \n        weight_decay: float, \n        loss_function,\n        max_epochs: int,\n    ):\n        self.network = models.resnet50(weights=weights)\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        self.network.fc = nn.Linear(\n            in_features=self.network.fc.in_features,\n            out_features=num_classes\n        )\n        \n        self.optimizer = optim.Adam(\n            self.network.parameters(), \n            lr=learning_rate,\n            weight_decay=weight_decay\n        )\n        \n        self.loss_function = loss_function \n        self.max_epochs = max_epochs\n    \n    def train(self, dataset: data.DataLoader):\n        \"\"\"\n        Function trains neural network on a given\n        training set of images\n        \n        Args:\n            - dataset (ImageDataset) - training set of images\n        \"\"\"\n        self.network.train()\n        \n        model = nn.DataParallel(self.network)\n        total_loss = []\n        \n        for epoch in range(self.max_epochs):\n            epoch_losses = []\n            \n            for labels, images in tqdm(dataset):\n                cuda_imgs = images.to(self.device)\n                predictions = model.forward(cuda_imgs).cpu()\n                loss = self.loss_function(predictions, labels)\n                \n                epoch_losses.append(loss.item())\n                \n                loss.backward()\n                self.optimizer.step()\n            \n            total_loss.append(sum(epoch_losses) / len(epoch_losses))\n            print('epoch - %s;' % (str(epoch + 1)))\n        return sum(total_loss) / len(total_loss)\n    \n    def evaluate(self, dataset: data.DataLoader):\n        \"\"\"\n        Function evaluates model on a given validation set\n        Args:\n            dataset - ImageDataset - non-augmented dataset with images\n        \"\"\"\n        self.network.eval()\n        model = nn.DataParallel(self.network)\n        \n        if len(dataset) == 0: return []\n        \n        predictions = []\n        with torch.no_grad():\n            \n            losses = []\n            for labels, images in tqdm(dataset):\n                cuda_imgs = images.to(self.device)\n                predictions = model.forward(cuda_imgs).cpu()\n                loss = self.loss_function(predictions, labels)\n                losses.append(loss.item())\n                \n        return sum(losses) / len(losses)\n    \n    \n    def predict(self, images: typing.List[Image.Image]):\n        \"\"\"\n        Function used for predicting\n        binary class of having 'face mask' put on or off\n        \n        Args:\n            images - list of PIL image objects\n        Returns:\n            list of predicted classes\n        \"\"\"\n        if not len(images): return \n        predictions = []\n        for image in dataset:\n            prediction = self.network.forward(image)\n            predictions.append(prediction)\n        return predictions\n    \ndef backward_trace_hook(module, grad_input, grad_output):\n    print('module - %s' % module)\n    print('grad input - ', grad_input)\n    print('grad output - ', grad_output)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:31.700703Z","iopub.execute_input":"2023-09-21T19:39:31.701231Z","iopub.status.idle":"2023-09-21T19:39:31.724289Z","shell.execute_reply.started":"2023-09-21T19:39:31.701194Z","shell.execute_reply":"2023-09-21T19:39:31.723185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MaskRecNet(\n    weights=models.ResNet50_Weights.DEFAULT,\n    num_classes=2,\n    learning_rate=3e-6,\n    loss_function=nn.CrossEntropyLoss(),\n    max_epochs=60,\n    weight_decay=0.01,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:31.726175Z","iopub.execute_input":"2023-09-21T19:39:31.72661Z","iopub.status.idle":"2023-09-21T19:39:32.956498Z","shell.execute_reply.started":"2023-09-21T19:39:31.726574Z","shell.execute_reply":"2023-09-21T19:39:32.955653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Neural Network","metadata":{}},{"cell_type":"code","source":"avg_loss = model.train(training_loader)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:39:32.957823Z","iopub.execute_input":"2023-09-21T19:39:32.958195Z","iopub.status.idle":"2023-09-21T19:54:12.987377Z","shell.execute_reply.started":"2023-09-21T19:39:32.958158Z","shell.execute_reply":"2023-09-21T19:54:12.986374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_loss","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:54:12.989155Z","iopub.execute_input":"2023-09-21T19:54:12.989833Z","iopub.status.idle":"2023-09-21T19:54:12.996382Z","shell.execute_reply.started":"2023-09-21T19:54:12.989778Z","shell.execute_reply":"2023-09-21T19:54:12.995311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating model on validation set","metadata":{}},{"cell_type":"code","source":"eval_loss = model.evaluate(validation_loader)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:54:12.997601Z","iopub.execute_input":"2023-09-21T19:54:12.998159Z","iopub.status.idle":"2023-09-21T19:54:15.193889Z","shell.execute_reply.started":"2023-09-21T19:54:12.998127Z","shell.execute_reply":"2023-09-21T19:54:15.193002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_loss","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:54:15.197858Z","iopub.execute_input":"2023-09-21T19:54:15.198472Z","iopub.status.idle":"2023-09-21T19:54:15.208928Z","shell.execute_reply.started":"2023-09-21T19:54:15.198438Z","shell.execute_reply":"2023-09-21T19:54:15.208079Z"},"trusted":true},"execution_count":null,"outputs":[]}]}