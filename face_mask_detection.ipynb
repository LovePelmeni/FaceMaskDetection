{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mloooo/notebook5a39d105b9?scriptVersionId=145248394\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-04T16:24:36.989153Z","iopub.execute_input":"2023-10-04T16:24:36.989855Z","iopub.status.idle":"2023-10-04T16:24:37.008014Z","shell.execute_reply.started":"2023-10-04T16:24:36.989813Z","shell.execute_reply":"2023-10-04T16:24:37.007103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport skimage\nimport numpy\nimport typing\nimport warnings \nimport os\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport pandas\nfrom PIL import Image\nimport seaborn\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:24:37.009858Z","iopub.execute_input":"2023-10-04T16:24:37.010379Z","iopub.status.idle":"2023-10-04T16:24:37.860043Z","shell.execute_reply.started":"2023-10-04T16:24:37.010349Z","shell.execute_reply":"2023-10-04T16:24:37.859087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_kaggle ='../input/face-mask-detection'\ndata_kaggle ='../input/face-mask-detection/dataset'\nwith_mask ='..../input/face-mask-detection/dataset/with_mask'\nwithout_mask='../input/face-mask-detection/dataset/without_mask'\n\nclass_data= ['with_mask','without_mask']\nlen_class_data = len(class_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:24:37.861227Z","iopub.execute_input":"2023-10-04T16:24:37.862142Z","iopub.status.idle":"2023-10-04T16:24:37.867576Z","shell.execute_reply.started":"2023-10-04T16:24:37.86211Z","shell.execute_reply":"2023-10-04T16:24:37.866086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_count = {}\ntrain_data = []\n\nfor i , class_data in tqdm(enumerate(class_data)):\n    class_folder = os.path.join(data_kaggle,class_data)\n    label = class_data\n    image_count[class_data] = []\n    \n    for path in os.listdir(os.path.join(class_folder)):\n        image_count[class_data].append(class_data)\n        train_data.append(['{}/{}'.format(class_data, path), i, class_data])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:24:37.868902Z","iopub.execute_input":"2023-10-04T16:24:37.869206Z","iopub.status.idle":"2023-10-04T16:24:37.887254Z","shell.execute_reply.started":"2023-10-04T16:24:37.869176Z","shell.execute_reply":"2023-10-04T16:24:37.886391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pandas.DataFrame(\n    train_data, \n    columns=['path', 'class', 'name']\n)\ndf['full_path'] = df['path'].apply(\n    lambda item: os.path.join(data_kaggle, item)\n)\ndf['image'] = df['full_path'].apply(func=lambda item: Image.open(item))\n\n\ndef validate_channels(img): \n    if numpy.array(img).shape[2] == 4:\n        img = Image.fromarray(\n        cv2.cvtColor(numpy.array(img), cv2.COLOR_RGBA2RGB))\n    return img\n\ndf['image'] = df['image'].apply(func=validate_channels)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:24:37.890082Z","iopub.execute_input":"2023-10-04T16:24:37.890596Z","iopub.status.idle":"2023-10-04T16:24:48.211204Z","shell.execute_reply.started":"2023-10-04T16:24:37.890566Z","shell.execute_reply":"2023-10-04T16:24:48.210211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seaborn.countplot(x=df['class'])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:24:48.212591Z","iopub.execute_input":"2023-10-04T16:24:48.212903Z","iopub.status.idle":"2023-10-04T16:24:48.426662Z","shell.execute_reply.started":"2023-10-04T16:24:48.212873Z","shell.execute_reply":"2023-10-04T16:24:48.425762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Smoothing and Filtering Noisy images","metadata":{}},{"cell_type":"code","source":"def bilateral_filtering(image, diameter: int, sigma_space: int, sigma_color: int):\n    \n    if not isinstance(image, numpy.ndarray):\n        image = numpy.array(image)\n        \n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    new_img = cv2.bilateralFilter(\n        src=gray_image, \n        d=diameter,\n        sigmaColor=sigma_color, \n        sigmaSpace=sigma_space,\n    )\n    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return rgb_image\n\ndef sharpen_image(blur_image, orig_image, sharpen_factor):\n    new_img = orig_image - blur_image \n    return orig_image + (sharpen_factor * new_img)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:24:48.428093Z","iopub.execute_input":"2023-10-04T16:24:48.428669Z","iopub.status.idle":"2023-10-04T16:24:48.435135Z","shell.execute_reply.started":"2023-10-04T16:24:48.428637Z","shell.execute_reply":"2023-10-04T16:24:48.434131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resizing Image","metadata":{}},{"cell_type":"code","source":"HEIGHT = 512\nWIDTH = 512","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:24:48.436571Z","iopub.execute_input":"2023-10-04T16:24:48.437088Z","iopub.status.idle":"2023-10-04T16:24:48.448598Z","shell.execute_reply.started":"2023-10-04T16:24:48.437057Z","shell.execute_reply":"2023-10-04T16:24:48.447735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adjusting image contrast","metadata":{}},{"cell_type":"code","source":"import numpy \n\ndef adjust_object_contrast(img, alpha: float, beta: float):\n    conv_img = cv2.convertScaleAbs(\n    img, alpha=alpha, beta=beta)\n    return conv_img\n\ndef gamma_correction(img, gamma):\n    float_img = img.astype(numpy.float32) / 255.0\n    corr_img = numpy.power(float_img, 1 / gamma)\n    new_img = (corr_img * 255).astype(numpy.uint8)\n    return new_img\n\ndef adjust_local_clahe(img, clip_limit: int=3.0, tile_grid_size: tuple=(8, 8)):\n    \n    lab_img = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n    l, a, b = cv2.split(lab_img)\n    \n    clahe = cv2.createCLAHE(clip_limit, tile_grid_size)\n    clahed_l = clahe.apply(l)\n    \n    merged_img = cv2.merge((clahed_l, a, b))\n    converted_rgb = cv2.cvtColor(img, cv2.COLOR_LAB2BGR)\n    return converted_rgb\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:24:48.449963Z","iopub.execute_input":"2023-10-04T16:24:48.450266Z","iopub.status.idle":"2023-10-04T16:24:48.459281Z","shell.execute_reply.started":"2023-10-04T16:24:48.450237Z","shell.execute_reply":"2023-10-04T16:24:48.458372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resizing images","metadata":{}},{"cell_type":"code","source":"def nearest_neighbor_interpolation(img: numpy.ndarray, height, width):\n    new_img = cv2.resize(img, (height, width), cv2.INTER_NEAREST)\n    return new_img\n\ndef bilinear_interpolation(img: numpy.ndarray, height, width):\n    new_img = cv2.resize(img, (height, width), cv2.INTER_LINEAR)\n    return new_img\n\ndef bicubic_interpolation(img: numpy.ndarray, height, width):\n    new_img = cv2.resize(img, (height, width), cv2.INTER_CUBIC)\n    return new_img","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:24:48.460654Z","iopub.execute_input":"2023-10-04T16:24:48.461199Z","iopub.status.idle":"2023-10-04T16:24:48.468662Z","shell.execute_reply.started":"2023-10-04T16:24:48.46117Z","shell.execute_reply":"2023-10-04T16:24:48.467844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nblurred_images = []\nfor image in df['image'].tolist():\n    \n    contrasted_img = adjust_local_clahe(numpy.array(image))\n    corrected_img = gamma_correction(numpy.array(image), gamma=1.8)\n    blurred_images.append(corrected_img)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:24:48.470047Z","iopub.execute_input":"2023-10-04T16:24:48.470374Z","iopub.status.idle":"2023-10-04T16:25:03.313167Z","shell.execute_reply.started":"2023-10-04T16:24:48.470339Z","shell.execute_reply":"2023-10-04T16:25:03.312203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HEIGHT = 512\nWIDTH = 512","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:03.314606Z","iopub.execute_input":"2023-10-04T16:25:03.315169Z","iopub.status.idle":"2023-10-04T16:25:03.31945Z","shell.execute_reply.started":"2023-10-04T16:25:03.315137Z","shell.execute_reply":"2023-10-04T16:25:03.31852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms \nfrom torchvision.transforms import v2 \nfrom PIL import Image\n\ntrain_transformations = [\n    transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=15),\n    transforms.Resize(size=(HEIGHT, WIDTH), \n    interpolation=Image.NEAREST),\n    v2.RandomAdjustSharpness(sharpness_factor=1.5),\n\n]\n\nvalidation_transformations = [\n    transforms.ToTensor(),\n    transforms.Resize(size=(HEIGHT, WIDTH), \n    interpolation=Image.NEAREST),\n]","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:03.321001Z","iopub.execute_input":"2023-10-04T16:25:03.321537Z","iopub.status.idle":"2023-10-04T16:25:06.294628Z","shell.execute_reply.started":"2023-10-04T16:25:03.321506Z","shell.execute_reply":"2023-10-04T16:25:06.293732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"from torch.utils import data\nimport torch\n\nclass ImageDataset(data.Dataset):\n    \n    def __init__(self, labels, images, transform=None):\n        self.labels = labels \n        self.images = images \n        self.transform = transforms.Compose(transform) if transform is not None else None\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, key):\n        if key >= len(self.labels): return \n        label = self.labels[key]\n        if self.transform is not None:\n            image = self.transform(self.images[key])\n        else: image = self.images[key]\n        return label, image","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:06.299099Z","iopub.execute_input":"2023-10-04T16:25:06.29953Z","iopub.status.idle":"2023-10-04T16:25:06.305264Z","shell.execute_reply.started":"2023-10-04T16:25:06.299505Z","shell.execute_reply":"2023-10-04T16:25:06.304362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = ImageDataset(\n    labels=df['class'].tolist(),\n    images=blurred_images,\n    transform=None\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:06.306562Z","iopub.execute_input":"2023-10-04T16:25:06.307065Z","iopub.status.idle":"2023-10-04T16:25:06.317345Z","shell.execute_reply.started":"2023-10-04T16:25:06.307036Z","shell.execute_reply":"2023-10-04T16:25:06.316367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:06.318542Z","iopub.execute_input":"2023-10-04T16:25:06.318922Z","iopub.status.idle":"2023-10-04T16:25:06.329218Z","shell.execute_reply.started":"2023-10-04T16:25:06.318828Z","shell.execute_reply":"2023-10-04T16:25:06.32833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:06.330543Z","iopub.execute_input":"2023-10-04T16:25:06.330839Z","iopub.status.idle":"2023-10-04T16:25:06.475301Z","shell.execute_reply.started":"2023-10-04T16:25:06.330808Z","shell.execute_reply":"2023-10-04T16:25:06.474283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices = numpy.arange(len(dataset.images))\ntrain_indices, test_indices = train_test_split(\n    indices, \n    stratify=dataset.labels, \n    test_size=0.3\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:06.476724Z","iopub.execute_input":"2023-10-04T16:25:06.477244Z","iopub.status.idle":"2023-10-04T16:25:06.484564Z","shell.execute_reply.started":"2023-10-04T16:25:06.477213Z","shell.execute_reply":"2023-10-04T16:25:06.483553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\ntraining_set = ImageDataset(\n    labels=numpy.array(dataset.labels)[train_indices],\n    images=numpy.array(dataset.images)[train_indices],\n    transform=train_transformations\n)\n\nvalidation_set = ImageDataset(\n    labels=numpy.array(dataset.labels)[test_indices],\n    images=numpy.array(dataset.images)[test_indices],\n    transform=validation_transformations\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:06.486256Z","iopub.execute_input":"2023-10-04T16:25:06.486683Z","iopub.status.idle":"2023-10-04T16:25:06.495073Z","shell.execute_reply.started":"2023-10-04T16:25:06.486649Z","shell.execute_reply":"2023-10-04T16:25:06.493922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(training_set)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:06.496665Z","iopub.execute_input":"2023-10-04T16:25:06.49729Z","iopub.status.idle":"2023-10-04T16:25:06.507609Z","shell.execute_reply.started":"2023-10-04T16:25:06.497256Z","shell.execute_reply":"2023-10-04T16:25:06.506384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(validation_set)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:06.508932Z","iopub.execute_input":"2023-10-04T16:25:06.509909Z","iopub.status.idle":"2023-10-04T16:25:06.51804Z","shell.execute_reply.started":"2023-10-04T16:25:06.509877Z","shell.execute_reply":"2023-10-04T16:25:06.516778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fg, ax = plt.subplots(1, 2)\nseaborn.countplot(ax=ax[0], x=training_set.labels)\nseaborn.countplot(ax=ax[1], x=validation_set.labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:06.519744Z","iopub.execute_input":"2023-10-04T16:25:06.520401Z","iopub.status.idle":"2023-10-04T16:25:06.832734Z","shell.execute_reply.started":"2023-10-04T16:25:06.520366Z","shell.execute_reply":"2023-10-04T16:25:06.831868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fg, ax = plt.subplots(3, 2)\nax[0, 0].imshow(training_set.images[0])\nax[0, 1].imshow(training_set.images[1])\nax[1, 0].imshow(training_set.images[2])\nax[1, 1].imshow(training_set.images[3])\nax[2, 0].imshow(training_set.images[4])\nax[2, 1].imshow(training_set.images[5])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:06.834178Z","iopub.execute_input":"2023-10-04T16:25:06.835101Z","iopub.status.idle":"2023-10-04T16:25:07.700337Z","shell.execute_reply.started":"2023-10-04T16:25:06.835069Z","shell.execute_reply":"2023-10-04T16:25:07.69948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating Image Processing","metadata":{}},{"cell_type":"code","source":"# for Transformed images\nfrom skimage.metrics import structural_similarity as ssim_scr\nfrom skimage import measure\n\ndef ssim_score(old_img, new_img, channel_axis):\n    return ssim_scr(old_img, new_img, channel_axis=channel_axis)\n\ndef normalized_cross_correlation(old_img, new_img):\n    \"\"\"\n    Function computes standard Normalized Cross Correlation\n    for given old and modified versions of the same image \n    \n    Args:\n        old_img (numpy.ndarray) - numpy.array object of old image\n        new_img (numpy.ndarray) - numpy.array object of the modified image\n    \"\"\"\n    img1 = (old_img - old_img.mean()) / old_img.std()\n    img2 = (new_img - new_img.mean()) / new_img.std()\n    return numpy.sum(img1 * img2) / (img1.shape[0] - 1)\n\n# For Noise-Recovered images\n\ndef niqe_score(distorted_image):\n    return measure.niqe(distorted_image)\n\ndef brisque_score(distorted_image):\n    return measure.brisque(distorted_image)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:07.701299Z","iopub.execute_input":"2023-10-04T16:25:07.701629Z","iopub.status.idle":"2023-10-04T16:25:07.837745Z","shell.execute_reply.started":"2023-10-04T16:25:07.701595Z","shell.execute_reply":"2023-10-04T16:25:07.83685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initializing data loaders","metadata":{}},{"cell_type":"code","source":"%%time\n\ntraining_loader = data.DataLoader(\n    training_set, \n    batch_size=32, \n    shuffle=True,\n)\n\nvalidation_loader = data.DataLoader(\n    validation_set,\n    batch_size=32,\n    shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:07.839019Z","iopub.execute_input":"2023-10-04T16:25:07.839922Z","iopub.status.idle":"2023-10-04T16:25:07.846533Z","shell.execute_reply.started":"2023-10-04T16:25:07.83989Z","shell.execute_reply":"2023-10-04T16:25:07.845655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\nmax_allocated = torch.cuda.max_memory_allocated()\n(max_allocated ** 2) / 1024","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:07.848012Z","iopub.execute_input":"2023-10-04T16:25:07.848475Z","iopub.status.idle":"2023-10-04T16:25:07.858211Z","shell.execute_reply.started":"2023-10-04T16:25:07.848445Z","shell.execute_reply":"2023-10-04T16:25:07.857331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initializing Classification Neural Network","metadata":{}},{"cell_type":"code","source":"from torchvision import models \nfrom torch import optim \nfrom torch import nn\nfrom tqdm import tqdm\nfrom torch import backends\n\nclass MaskRecNet(object):\n    \n    \"\"\"\n    Implementation of the ResNet50 Neural Network \n    for classifying human as 'with' or 'without' face mask\n    \"\"\"\n    def __init__(self, \n        weights, \n        num_classes: int,\n        learning_rate: float, \n        weight_decay: float, \n        loss_function,\n        max_epochs: int,\n    ):\n        self.network = models.resnet50(weights=weights)\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        self.network.fc = nn.Linear(\n            in_features=self.network.fc.in_features,\n            out_features=num_classes\n        )\n        \n        self.optimizer = optim.Adam(\n            self.network.parameters(), \n            lr=learning_rate,\n            weight_decay=weight_decay\n        )\n        \n        self.loss_function = loss_function \n        self.max_epochs = max_epochs\n    \n    \n    def freeze_layers(self, num_layers_to_freeze):\n        \"\"\"\n        Function freezes first N number of layers\n        in the network\n        \"\"\"\n        for i, param in enumerate(self.network.parameters()):\n            if i < num_layers_to_freeze:\n                param.requires_grad = False\n            else:\n                break\n            \n    def unfreeze_layers(self):\n        \"\"\"\n        Function unfreezes all\n        freezed layers of the network\n        \"\"\"\n        for idx, param in enumearte(self.network.parameters()):\n            if not param.requires_grad:\n                param.requires_grad = True\n            \n    def train(self, dataset: data.DataLoader):\n        \"\"\"\n        Function trains neural network on a given\n        training set of images\n        \n        Args:\n            - dataset (ImageDataset) - training set of images\n        \"\"\"\n        self.network.train()\n        \n        model = nn.DataParallel(self.network)\n        total_loss = []\n        \n        for epoch in range(self.max_epochs):\n            epoch_losses = []\n            \n            for labels, images in tqdm(dataset):\n                cuda_imgs = images.to(self.device)\n                predictions = model.forward(cuda_imgs).cpu()\n                loss = self.loss_function(predictions, labels)\n                \n                epoch_losses.append(loss.item())\n                \n                loss.backward()\n                self.optimizer.step()\n            \n            total_loss.append(sum(epoch_losses) / len(epoch_losses))\n            print('epoch - %s;' % (str(epoch + 1)))\n        return sum(total_loss) / len(total_loss)\n    \n    def evaluate(self, dataset: data.DataLoader):\n        \"\"\"\n        Function evaluates model on a given validation set\n        Args:\n            dataset - ImageDataset - non-augmented dataset with images\n        \"\"\"\n        self.network.eval()\n        model = nn.DataParallel(self.network)\n        \n        if len(dataset) == 0: return []\n        \n        predictions = []\n        with torch.no_grad():\n            \n            losses = []\n            for labels, images in tqdm(dataset):\n                cuda_imgs = images.to(self.device)\n                predictions = model.forward(cuda_imgs).cpu()\n                loss = self.loss_function(predictions, labels)\n                losses.append(loss.item())\n                \n        return sum(losses) / len(losses)\n    \n    \n    def predict(self, images: typing.List[Image.Image]):\n        \"\"\"\n        Function used for predicting\n        binary class of having 'face mask' put on or off\n        \n        Args:\n            images - list of PIL image objects\n        Returns:\n            list of predicted classes\n        \"\"\"\n        if not len(images): return \n        predictions = []\n        for image in dataset:\n            prediction = self.network.forward(image)\n            predictions.append(prediction)\n        return predictions\n    \ndef backward_trace_hook(module, grad_input, grad_output):\n    print('module - %s' % module)\n    print('grad input - ', grad_input)\n    print('grad output - ', grad_output)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:07.85979Z","iopub.execute_input":"2023-10-04T16:25:07.860459Z","iopub.status.idle":"2023-10-04T16:25:07.875877Z","shell.execute_reply.started":"2023-10-04T16:25:07.860425Z","shell.execute_reply":"2023-10-04T16:25:07.874881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MaskRecNet(\n    weights=models.ResNet50_Weights.DEFAULT,\n    num_classes=2,\n    learning_rate=3e-6,\n    loss_function=nn.CrossEntropyLoss(),\n    max_epochs=60,\n    weight_decay=0.01,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:07.877333Z","iopub.execute_input":"2023-10-04T16:25:07.877689Z","iopub.status.idle":"2023-10-04T16:25:08.878656Z","shell.execute_reply.started":"2023-10-04T16:25:07.877616Z","shell.execute_reply":"2023-10-04T16:25:08.877691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Freezing layers for transfer learning task","metadata":{}},{"cell_type":"code","source":"model.freeze_layers(45)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:08.880023Z","iopub.execute_input":"2023-10-04T16:25:08.880582Z","iopub.status.idle":"2023-10-04T16:25:08.885005Z","shell.execute_reply.started":"2023-10-04T16:25:08.880549Z","shell.execute_reply":"2023-10-04T16:25:08.884181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Neural Network","metadata":{}},{"cell_type":"code","source":"avg_loss = model.train(training_loader)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:25:08.886387Z","iopub.execute_input":"2023-10-04T16:25:08.886686Z","iopub.status.idle":"2023-10-04T16:39:29.036158Z","shell.execute_reply.started":"2023-10-04T16:25:08.886659Z","shell.execute_reply":"2023-10-04T16:39:29.035189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_loss","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:39:29.037757Z","iopub.execute_input":"2023-10-04T16:39:29.038429Z","iopub.status.idle":"2023-10-04T16:39:29.04491Z","shell.execute_reply.started":"2023-10-04T16:39:29.038394Z","shell.execute_reply":"2023-10-04T16:39:29.043976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating model on validation set","metadata":{}},{"cell_type":"code","source":"eval_loss = model.evaluate(validation_loader)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:39:29.04622Z","iopub.execute_input":"2023-10-04T16:39:29.046779Z","iopub.status.idle":"2023-10-04T16:39:30.937507Z","shell.execute_reply.started":"2023-10-04T16:39:29.046747Z","shell.execute_reply":"2023-10-04T16:39:30.936609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_loss","metadata":{"execution":{"iopub.status.busy":"2023-10-04T16:39:30.938798Z","iopub.execute_input":"2023-10-04T16:39:30.939669Z","iopub.status.idle":"2023-10-04T16:39:30.946147Z","shell.execute_reply.started":"2023-10-04T16:39:30.939637Z","shell.execute_reply":"2023-10-04T16:39:30.945209Z"},"trusted":true},"execution_count":null,"outputs":[]}]}